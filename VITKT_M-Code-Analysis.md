# VITKT_M代码解读

## 1. 代码结构

## 2. 测试代码
由于原作者的代码结构过于庞杂，这里首先从测试代码入手。
此外，测试代码包含了tracker的主体内容，是理解整体代码的线索。
测试代码可能涉及多个代码文件，因此这里并不按照代码文件的情况对内容进行区分，而是直接从逻辑角度进行梳理。

### 2.1 test_tracker_vot.py
vot官方提供的脚本编写规范，用于将自己构建的tracker在vot数据集上进行测试。

阈值参数配置（14-21）

通过trax深度学习开源库来初始化vot控制器和tracker（23-29）

执行逐帧跟踪（31-39）

### 2.2 vitkt_m.py

#### 2.2.1 lof计算相关函数
理论主要参考：
https://blog.csdn.net/FutureStone/article/details/127987250

lof函数对数据进行处理，返回clf方法（38-41）
计算LOF，根据阈值划分离群点和正常点（44-50）

#### 2.2.2 bbox转化函数
归一化的左上角点和右下角点坐标确定的bbox转化真实坐标的左上角点和宽高bbox表示（53-62）

#### 2.2.3 Tracker主函数
大体可分为6个部分：
（1）初始化
（2）KeepTrack相关部分
（3）运动模型相关部分
（4）metric相关部分
（5）本地tracker相关部分
（6）跟踪主体流程

按照类中的函数可细化分为：总初始化、KeepTrack初始化、KeepTrack评估、运动模型初始化、运动模型评估、metric初始化、metric特征获取、metric评估、本地tracker初始化、本地tracker跟踪执行、跟踪总流程执行。

只有当KeepTrack和本地tracker同时失效的时候，才会启用运动模型。

**（1）初始化**
初始化参数p、索引i、失败计数器、获取边界框并转化为角点形式、获取中心点+宽高的表示形式。
用输入图像和init_gt1初始化keeptrack、本地tracker、metric和运动模型。

**（2）KeepTrack相关**
KeepTrack算法的实现是使用pytracking的包，利用Tracker类直接调用keeptrack模型。

初始化部分的总体流程是pytracking中的跟踪器在代码实现的一种使用方法（93-106）

评估部分是tracker实际执行部分，在经过图像和初始目标位置的初始化后，通过单帧图像的输入获取目标得分和目标边界框（源码中用state表示）
然后将目标位置和原图传输给metric评估，从而得到特征距离和离群分数，这些输出内容都是基于初始帧的目标特征和tracker获取的当前帧目标特征得到的。（具体内容参考metric部分）

**（3）运动模型相关**
通过调用LTR模块中的运动模型进行构建，直接加载训练好的网络+权重文件，直接获得可用模型。

初始化一个1×30×4大小的numpy矩阵作为运动模型的初始化输入。
构建输入列表，加入归一化的目标边界框。（114-128）

维度变换+tensor化（131-133）
通过运动模型获取预测的当前帧目标位置，并移除一个变量维度（134-137）
对得到的预测目标位置进行评估：当预测目标位置超出图像范围、目标尺寸过小（宽高小于3像素）、目标尺寸过大（超出图像尺寸）时，返回预测bbox并直接定义特征距离和离群因子为100；当预测目标位置正常时，采用metric计算特征距离和离群得分。（138-142）

**（4）metric相关**
metric模块主要用于获取特征距离和离群因子得分。

metric模型竟然是一个网络...（其实想想也是合理的，因为其需要进行目标模板的特征提取）
基础结构是resnet50（对于某些层的参数做了一定的修改），同时附加了Distance模块作距离特征提取，CLass模块作为分类器，类别数定义为1120，也就是说最后获取的是一个1120维度的向量。（145-149）

定义一个1×3×107×107维度的临时变量，作为输入初始化运动模型。（150-153）

对第一帧的目标位置进行特征提取，获得anchor_feature，作为特征距离计算的基准。（154-156）

通过SampleGenerator来生成目标模板，具体方法是通过随机高斯函数对初始帧目标的模板进行扩增，通过随机目标中心点和改变采样尺寸的方式获得多个目标模板，然后从其中筛选出符合规定IoU要求的目标模板（默认为范围是0.7-1.0）。（158-161）
如果目标模板数量不足10，则降低IoU要求，直到获取10个以上目标模板为止。（162-165）

对目标模板集合进行特征提取，获得gt_pos_features。（166-167）

离群因子模型基于gt_pos_features，阈值设为2.5。（169-170）

特征获取单元：分别通过区域提取、区域处理、和metric模型特征提取3个步骤完成metric特征提取过程。（172-178）
其中，模板区域提取部分通过将所有目标模板裁剪为3×107×107维度，进行统一处理。
区域处理主要对像素进行归一化处理。
metric模型的特征提取部分主要就是用于将归一化后的模板集合进行特征提取，输出为不同目标模板的特征集合。

metric评估部分：
基于上述的metric初始化和特征获取单元，获取当前帧的目标模板特征，将其与初始帧特征进行比较，从而获得特征距离和离群值。（100-108）

**（5）本地Tracker相关**
本地Tracker作者主要采用的是以ViT为特征提取器的STARK变种。

与KeepTrack一样，初始化实现过程中，遵循类似的流程，部分参数有出入。（190-200，这套流程可以作为跟踪器的构建范式）

本地Tracker执行函数：（202-208）
首先将图像逐帧输入跟踪器的跟踪执行单元，从而获得输出；
分别从输入中获取目标bbox和置信度分数conf；
将预测的bbox作为下一帧的参考，并将其转化为本地state形式；
通过metric评估，获取特征距离、离群值、metric特征。

**（6）跟踪主体程序**
帧索引+1（213）
本地Tracker和KeepTrack分别获得，当前state、conf分数、特征距离、离群值，本地Tracker还会额外获取metric特征。（214-215）
初始化KeepTrack使能为0。（216）
获取相邻帧目标中心位置偏移距离。（217-219）

**进入判断流程，这将决定启用哪一个Tracker还是运动模型：**

**判断块1（221-222）：用于更新匹配模板**
如果两个Tracker得到的目标置信度分数都大于参数中的更新分数阈值（默认值是0.8）。
则将目标初始帧基础特征更新为本地Tracker获取的metric特征。

**判断块2（223-233）：用于判断是否启用KeepTrack**
如果本地Tracker的置信度分数小于置信度分数阈值（默认是0.7），
并且满足下面条件之一即可：
a. KeepTrack给出的置信度分数大于置信度分数阈值
b. KeepTrack特征距离小于本地Tracker的特征距离
c. KeepTrack离群值小于本地Tracker的离群值

KeepTrack使能赋值为1
last_gt、state、置信度得分、特征距离、离群因子、目标中心偏移距离均更新为KeepTrack模型获取的相关值。

**判断块3（234-244）：用于判断是否启用运动模型**
如果累计帧大于等于30，并且本地Tracker得到的目标置信度分数小于置信度分数阈值（默认是0.7），并且目标中心偏移距离大于偏移距离阈值（默认是0.55，归一化后）

通过运动模型执行程序获取bbox、特征距离、离群因子。
如果特征距离或离群因子层面，运动模型小于本地Tracker，则将last_gt、state、置信度得分、特征距离、离群因子、目标中心偏移距离均更新为运动模型获取的相关值。

**判断块4（246-250）：**
即便不使用KeepTrack的输出结果，但还是要更新KeepTrack的类内参数，便于下一次进行跟踪。

**判断快5（252-255）：**
当帧超过30时，运动模型的输入序列会pop出第一帧的输入，并将当前帧输入添加在列表末端。
也就是说，所使用的运动模型最多只能利用30帧进行运动预测。

程序的最后获取目标的尺寸和中心位置。
返回目标的位置（x1，y1，w，h），置信度分数，特征距离，离群值。